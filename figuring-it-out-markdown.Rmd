---
title: "TrainTracker: Predicting New Jersey Transit Delays & Unifying Transit Information"
author: "Trevor Kapuvari & Timothy Oliver"
date: "15 December 2023"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: hide
---

# Motivation

Trains are a timeless mode of transportation that has revolutionized the world. As we aim to improve their reliability and accessibility, it is crucial to understand their performance records and allow riders to stay informed on travel updates, train reliability, and enable them to plan their trips accordingly. Hence, we have dedicated this brief to developing a two-part prediction model to forecast train delays. 

This analysis serves as an experimental use-case that can be replicated to other transit regions in the United States and further enable inter-state travel in order to efficiently utilize train networks. 

```{r clear_environment, include=F, results = 'hide'}
rm(list=ls())
```


```{r setup, include=FALSE}

# global options for knitting chunks
local({
  hook_output <- knitr::knit_hooks$get('output')
  knitr::knit_hooks$set(output = function(x, options) {
    if (!is.null(options$max.height)) options$attr.output <- c(
      options$attr.output,
      sprintf('style="max-height: %s;"', options$max.height)
    )
    hook_output(x, options)
  })
})
knitr::opts_chunk$set(echo = TRUE,message=F,warning=F)



library(summarytools)
library(stargazer)
library(vtable)
library(tidyverse)
library(tidycensus)
library(sf)
library(spdep)
library(caret)
library(ckanr)
library(FNN)
library(grid)
library(gridExtra)
library(ggcorrplot) # plot correlation plot
library(corrr)      # another way to plot correlation plot
library(kableExtra)
library(jtools)     # for regression model plots
library(ggstance) # to support jtools plots
library(ggpubr)    # plotting R^2 value on ggplot point scatter
library(broom.mixed) # needed for effects plots
library(tufte)
library(viridis)
library(RSocrata)
library(classInt)
library(spatstat)
library(pscl)
library(plotROC)
library(pROC)
library(lubridate)
library(ROSE)
library(tigris)
library(knitr)
library(RSocrata)
library(gganimate)


# functions and data directory
root.dir = "https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/DATA/"


source("https://raw.githubusercontent.com/urbanSpatial/Public-Policy-Analytics-Landing/master/functions.r")
source("themes/plotTheme_TO.r")
# source("functions/quantileBreaks.r")

palette2 <- c("#981FAC","#FF006A")
palette5 <- c("#25CB10", "#5AB60C", "#8FA108",   "#C48C04", "#FA7800")
palette5a <- c("#eff3ff","#bdd7e7","#6baed6","#3182bd","#08519c")
palette4a <- c("#D2FBD4","#92BCAB","#527D82","#123F5A")
palette2a <- c("#6baed6","#08519c")

palette9 <- viridis(9)

options(scipen=999)

```

# Data Sources

Our initial dataset is derived from Kaggle's NJ Transit & Amtrak Rail Performance. Due to the high volume of data, we narrowed the scope of the model to focus on April & May 2020. The data features Amtrak trains between New York & New Jersey, as well as recording lines from NJ Transit. This sample provides insight on performance at peak train-use because the Northeast Corridor, the main rail studied, is considered the busiest passenger rail line in the United States. Within the data we are able to explore the individual train's scheduled time, actual time, planned stations, and sequence in train line over the course of two months. That information allows our model to predict a delay based on its past performance and time of the week/day to detect any temporal patterns that may exist. 


Source: https://www.kaggle.com/datasets/pranavbadami/nj-transit-amtrak-nec-performance


```{r kaggle_data, results='hide'}
if (!dir.exists("data/Kaggle_transit&amtrak_data/")){
unzip("data/Kaggle_transit&amtrak_data.zip",exdir="data/Kaggle_transit&amtrak_data")
  
  # archive <- archive("data/testing/Kaggle_transit&amtrak_data.7z")
  # trial <- archive_read(archive=archive,file=archive$path[28],format='7zip')
}

datApr2020 <- read.csv("data/Kaggle_transit&amtrak_data/2020_04.csv")
datMay2020 <- read.csv("data/Kaggle_transit&amtrak_data/2020_05.csv")


datApr2020 <- datApr2020 %>%
  mutate(interval60 = floor_date(ymd_hms(scheduled_time), unit = "hour"),
         interval15 = floor_date(ymd_hms(scheduled_time), unit = "15 mins"),
         interval1 = floor_date(ymd_hms(scheduled_time), unit = "min"),
         week = week(interval60),
         dotw = wday(interval60,label=T),
         delayed = ifelse(delay_minutes > 0,TRUE,FALSE))

datMay2020 <- datMay2020 %>%
  mutate(interval60 = floor_date(ymd_hms(scheduled_time), unit = "hour"),
         interval15 = floor_date(ymd_hms(scheduled_time), unit = "15 mins"),
         interval1 = floor_date(ymd_hms(scheduled_time), unit = "min"),
         week = week(interval60),
         dotw = wday(interval60,label=T),
         delayed = ifelse(delay_minutes > 0,TRUE,FALSE))

nj_trans_stations <- st_read("data/Rail_Stations_of_NJ_Transit.geojson")%>% st_transform(crs="ESRI:102711")

nj_trans_lines <- st_read("data/Rail_Lines_of_NJ_Transit.geojson")%>% st_transform(crs="ESRI:102711")


may_w_stations <- merge(x= nj_trans_stations,y=datMay2020,by.x="STATION_ID",by.y="from")%>%
  rename(from_station = STATION_ID,
         fromLat = LATITUDE, fromLon = LONGITUDE, 
         from_atis_id = ATIS_ID, from_muni = MUNICIPALITY,
         from_rail_service = RAIL_SERVICE)%>%
  select(-OBJECTID_1,-LINE_CODE)%>%
  st_drop_geometry()%>%
  merge(y=nj_trans_stations,by.x="to",by.y="STATION_ID")%>%
  rename(to_station = to,
         toLat = LATITUDE, toLon = LONGITUDE, 
         to_atis_id = ATIS_ID, to_muni = MUNICIPALITY,
         to_rail_service = RAIL_SERVICE) %>%
  select(-OBJECTID_1)%>%
  st_drop_geometry() %>%
  merge(y=nj_trans_lines,by="LINE_CODE")%>%
  select(-OBJECTID)%>%
  st_drop_geometry() %>%
  st_set_geometry(value="geometry.x")

apr_w_stations <- merge(x= nj_trans_stations,y=datApr2020,by.x="STATION_ID",by.y="from")%>%
  rename(from_station = STATION_ID,
         fromLat = LATITUDE, fromLon = LONGITUDE, 
         from_atis_id = ATIS_ID, from_muni = MUNICIPALITY,
         from_rail_service = RAIL_SERVICE)%>%
  select(-OBJECTID_1,-LINE_CODE)%>%
  st_drop_geometry()%>%
  merge(y=nj_trans_stations,by.x="to",by.y="STATION_ID")%>%
  rename(to_station = to,
         toLat = LATITUDE, toLon = LONGITUDE, 
         to_atis_id = ATIS_ID, to_muni = MUNICIPALITY,
         to_rail_service = RAIL_SERVICE) %>%
  select(-OBJECTID_1)%>%
  st_drop_geometry() %>%
  merge(y=nj_trans_lines,by="LINE_CODE")%>%
  # rename(toLat = LATITUDE, toLon = LONGITUDE, 
  #        to_atis_id = ATIS_ID, to_muni = MUNICIPALITY,
  #        to_rail_service = RAIL_SERVICE,
  #        to_line_code = LINE_CODE) %>%
  select(-OBJECTID)%>%
  st_drop_geometry() %>%
  st_set_geometry(value="geometry.x")

delayprobability <- datMay2020 %>%
  mutate(delay_prob = delay_minutes * 0)

delayprobability <- glm(delay_prob ~ date + train_id + stop_sequence + from_id + to_id + week, data = delayprobability, family="binomial")
summary(delayprobability)

rm(datMay2020,datApr2020)
```


Additional data from the American Community Survey (ACS) provided us insight on commuter data for New York, New Jersey, and southeast Pennsylvania area. The data here provided us the sense of urgency and importance these rail lines are to commuters. Areas surrounding New York City greatly rely on trains and public transit for commuting or everyday travel as seen with [recent articles](https://www.northjersey.com/story/news/transportation/2023/11/01/nj-transit-bus-ridership-bounced-back-covid/71394013007/) detailing NJ Transit approaching pre-COVID levels while other areas have struggled to reclaim riders. 

```{r wrangling, results='hide',cache=T}

census <- 
  get_acs(geography = "county", 
          variables = c("B01003_001", "B19013_001", 
                        "B02001_002", "B08013_001",
                        "B08012_001", "B08301_001", 
                        "B08301_010", "B01002_001"), 
          year = 2021, 
          geometry = TRUE, 
          output = "wide") %>%
  rename(Total_Pop =  B01003_001E,
         Med_Inc = B19013_001E,
         Med_Age = B01002_001E,
         White_Pop = B02001_002E,
         Travel_Time = B08013_001E,
         Num_Commuters = B08012_001E,
         Means_of_Transport = B08301_001E,
         Total_Public_Trans = B08301_010E)%>%
  st_transform(crs="EPSG:4326")

tracts <- 
  get_acs(geography = "tract", 
          variables = c("B01003_001", "B19013_001", 
                        "B02001_002", "B08013_001",
                        "B08012_001", "B08301_001", 
                        "B08301_010", "B01002_001"), 
          year = 2021, 
          geometry = TRUE,
          state="NJ",
          output = "wide") %>%
  rename(Total_Pop =  B01003_001E,
         Med_Inc = B19013_001E,
         Med_Age = B01002_001E,
         White_Pop = B02001_002E,
         Travel_Time = B08013_001E,
         Num_Commuters = B08012_001E,
         Means_of_Transport = B08301_001E,
         Total_Public_Trans = B08301_010E)%>%
  st_transform(crs="EPSG:4326")

threeStates = census%>%filter(grepl("New Jersey",NAME)|grepl("Pennsylvania",NAME)|grepl("New York",NAME))
nj = census%>%filter(grepl("New Jersey",NAME))

rm(census)
```

# Means of Transport 

This maps indicates the importance of using NYC and NJ Transit as our initial case-study area for our model. Commuting by train is underused in most areas of the country especially when distant from any major cities. New Jersey has a special case of being between two major metropolitan areas, New York and Philadelphia. This location makes the state optimal for long-distance train studies. Even when the majority of New York State and Pennsylvania have lower numbers of commuters, denoted by blue, New Jersey's roughly purple palette proves the importance of trains in the regional economy. 

```{r ThreeState Commuters by Rail}

ggplot()+
  geom_sf(data=threeStates,aes(fill = Means_of_Transport))+
  labs(title = "Daily Passenger Train Commuters", fill = "Average Daily Commuters by Rail")+
  scale_y_continuous(labels = scales::comma_format())+ #why not comma separation wtf 
  scale_fill_gradient(low = "royalblue", high = "red")+ 
  plotTheme()+
  theme(panel.background=element_rect(
        fill = "#fcfcf4",
        colour = NA),
        panel.grid.major=element_blank(),
        axis.text=element_blank())


```



```{r line_station_panel,cache=T}
# length(unique(may_w_stations$interval60)) * length(unique(may_w_stations$from_id))


study.panelM <- 
  expand.grid(interval60=unique(may_w_stations$interval60), 
              from_id = unique(may_w_stations$from_id)) %>%
  left_join(., may_w_stations %>%
              # changed fromLon & Lat to fromCountyLon & Lat
              select(train_id, from_id, line,delay_minutes)%>% # Origin.Tract,
              distinct() %>%
              group_by(from_id) %>%
              slice(1))

study.panelA <- 
  expand.grid(interval60=unique(apr_w_stations$interval60), 
              from_id = unique(apr_w_stations$from_id)) %>%
  left_join(., apr_w_stations %>%
              # changed fromLon & Lat to fromCountyLon & Lat
              select(train_id, from_id, line,delay_minutes)%>% # Origin.Tract,
              distinct() %>%
              group_by(from_id) %>%
              slice(1))


ride.panelM <- may_w_stations %>%
  mutate(Trip_Counter = 1) %>%
  right_join(study.panelM) %>% 
  # changed fromLon & Lat to fromCountyLon & Lat
  group_by(interval60, from_id, to_id, from_station, to_station, delay_minutes,SHAPE_Length) %>%
  rename(line_length = SHAPE_Length) %>%
  summarize(Trip_Count = sum(Trip_Counter, na.rm=T)) %>%
  ungroup() %>%
  filter(is.na(from_id) == FALSE) %>%
  mutate(week = week(interval60),
         dotw = wday(interval60, label = TRUE)) %>%
  # filter(is.na(Origin.County) == FALSE) %>%
  # left_join(study.panel, threeStates %>%
  #             as.data.frame()) %>% # extra parenthesis
              # select(-geometry), by = c("Origin.Tract" = "GEOID")) %>%
  arrange(from_id, interval60) %>% 
  mutate(lagHour = dplyr::lag(delay_minutes,1),
         lag2Hours = dplyr::lag(delay_minutes,2),
         lag3Hours = dplyr::lag(delay_minutes,3),
         lag4Hours = dplyr::lag(delay_minutes,4),
         lag12Hours = dplyr::lag(delay_minutes,12),
         lag1day = dplyr::lag(delay_minutes,24)) %>%
         # # Indigenous Peoples' (Columbus) Day is federally recognized
         # #  but not an official city holiday of Austin
         # ## I include it to account for holiday lag
         # holiday = ifelse(yday(interval60) == 282,1,0)) %>%
   mutate(day = yday(interval60)) # %>%
   # mutate(holidayLag = case_when(dplyr::lag(holiday, 1) == 1 ~ "PlusOneDay",
   #                               dplyr::lag(holiday, 2) == 1 ~ "PlusTwoDays",
   #                               dplyr::lag(holiday, 3) == 1 ~ "PlusThreeDays",
   #                               dplyr::lead(holiday, 1) == 1 ~ "MinusOneDay",
   #                               dplyr::lead(holiday, 2) == 1 ~ "MinusTwoDays",
   #                               dplyr::lead(holiday, 3) == 1 ~ "MinusThreeDays"),
   #       holidayLag = ifelse(is.na(holidayLag) == TRUE, 0, holidayLag))

ride.panelA <- apr_w_stations %>%
  mutate(Trip_Counter = 1) %>%
  right_join(study.panelA) %>% 
  # changed fromLon & Lat to fromCountyLon & Lat
  group_by(interval60, from_id, to_id, from_station, to_station, delay_minutes,SHAPE_Length) %>%
  rename(line_length = SHAPE_Length) %>%
  summarize(Trip_Count = sum(Trip_Counter, na.rm=T)) %>%
  ungroup() %>%
  filter(is.na(from_id) == FALSE) %>%
  mutate(week = week(interval60),
         dotw = wday(interval60, label = TRUE)) %>%
  # filter(is.na(Origin.County) == FALSE) %>%
  # left_join(study.panel, threeStates %>%
  #             as.data.frame()) %>% # extra parenthesis
              # select(-geometry), by = c("Origin.Tract" = "GEOID")) %>%
  arrange(from_id, interval60) %>% 
  mutate(lagHour = dplyr::lag(delay_minutes,1),
         lag2Hours = dplyr::lag(delay_minutes,2),
         lag3Hours = dplyr::lag(delay_minutes,3),
         lag4Hours = dplyr::lag(delay_minutes,4),
         lag12Hours = dplyr::lag(delay_minutes,12),
         lag1day = dplyr::lag(delay_minutes,24)) %>%
         # # Indigenous Peoples' (Columbus) Day is federally recognized
         # #  but not an official city holiday of Austin
         # ## I include it to account for holiday lag
         # holiday = ifelse(yday(interval60) == 282,1,0)) %>%
   mutate(day = yday(interval60)) # %>%
   # mutate(holidayLag = case_when(dplyr::lag(holiday, 1) == 1 ~ "PlusOneDay",
   #                               dplyr::lag(holiday, 2) == 1 ~ "PlusTwoDays",
   #                               dplyr::lag(holiday, 3) == 1 ~ "PlusThreeDays",
   #                               dplyr::lead(holiday, 1) == 1 ~ "MinusOneDay",
   #                               dplyr::lead(holiday, 2) == 1 ~ "MinusTwoDays",
   #                               dplyr::lead(holiday, 3) == 1 ~ "MinusThreeDays"),
   #       holidayLag = ifelse(is.na(holidayLag) == TRUE, 0, holidayLag))

```


# New Jersey Transit Map

The map below depicts New Jersey Transit lines that we predicted delays for in the model. Predictions within the model ranged between 1 minute to almost 2 hours, for the purpose of the analysis and due to available data, we are focusing our attention of these lines. 

```{r view_stations}

ggplot()+
  geom_sf(data=nj%>%st_transform(st_crs(nj_trans_stations)),color = "white",fill="darkgray")+
  geom_sf(data=nj_trans_stations, color="black")+
  geom_sf(data=nj_trans_lines,aes(color = LINE_NAME))+
  labs(title = "New Jersey Transit Map", color = "Train Line")+
  plotTheme()+
  theme(panel.background=element_rect(
        fill = "#fcfcf4",
        colour = NA),
        panel.grid.major=element_blank(),
        axis.text=element_blank())

```

# Exploratory Analysis

## Temporal Train Cycle 

The graph below shows a temporal cycle of train trips by NJ Transit. One important factor when accounting for delays, whether the cause or the effects, is the time of day. The pattern between peak hours and when there are few trains can assist the model in detecting patterns in delays caused by time, and how greatly that effects the probability or length of the delay. 

```{r plots}


ggplot(may_w_stations %>%
         group_by(interval60) %>%
         tally())+
  geom_line(aes(x = interval60, y = n))+
  labs(title="Train Trips in NYC Area (NJ Transit), May 2020",
       x="Date",
       y="Number of Trips")+
  plotTheme()+
  coord_cartesian(ylim=c(0,300))

```



## Delay Count

The value of trains to the region also is rooted in their reliability and people's understanding of such. Recorded NJ Transit train trips in May 2020 shows that `r nrow(may_w_stations[may_w_stations$delayed==T,])` of the total `r nrow(may_w_stations[is.na(may_w_stations$delayed)==F,])` trips did not arrive at scheduled times--roughly 70% of all trips. This graph records all delays regardless of severity, but still means there was a higher likelihood of a commuter's trip being delayed than not. It is important to understand some delays recorded were negligible (less than 10 minutes), yet others were almost 2 hours. Distinguishing between negligible delays is what riders would find useful before they occurs, emphasizing the need for a reliable method of predicting the impact of a delay alongside its probability.  



```{r bar_plot}

ggplot(may_w_stations,mapping=aes(x=delayed))+
  geom_bar(aes(fill=delayed,show.legend=F))+
  geom_text(aes(label=..count..),stat="count",color="white",vjust=1.5)+
  labs(title="Delayed Train Trip Count for NJ Transit, May 2020",
       y="Number of trips",
       x = "Delayed")+
  guides(fill=guide_legend(title = "Delayed Train?"))+
  scale_color_manual(labels=c("False","True","Amtrak"),
                     values = c(GRAY9,BLUE3,GREEN3) # did nothing?
                     )+
  plotTheme()+
  theme(panel.border = element_blank(),
        panel.background = element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_blank())



```


## Tracking Station Business 

The graph below shows that the majority of stations each day only saw one or two train stops every hour. This frequency seen at majority of stations indicates a level of importance the timing these trains have in terms of efficiency. Large delays for stops that do not have multiple trains can result in riders having few to no alternative route options and succumbing to the lateness brought by delays. Places that see more trains are also jeopardized by delays for different reasons. If large enough, delays can create rail congestion and in turn propagate the delay to other trains that would have otherwise been timely. 

```{r from_station}
ggplot(may_w_stations %>%
         group_by(interval60, from_station) %>%
         tally())+
  geom_histogram(aes(n), binwidth = 1, color = GRAY8)+
  labs(title="Train Trips per Hour. NJ Transit & Amtrak Area, May 2020",
       x="Trip Counts", 
       y="Number of Stops")+
  plotTheme()+
  coord_cartesian(xlim=c(0,10))
```


<<<<<<< HEAD
```{r probability of delay attempt, eval=F,include=F}
delayprobability <- datMay2020 %>%
  mutate(delay_prob = delay_minutes * 0)

delayprobability <- glm(delay_prob ~ date + train_id + stop_sequence + from_id + to_id + week, data = delayprobability, family="binomial")
summary(delayprobability)



```


=======
>>>>>>> 97bf75e09dcc79ad761d71adbf2569f16d276655

```{r geometry_in_panel,eval=F,include=F}
ride.panel <- may_census %>%
  mutate(Trip_Counter = 1) %>%
  right_join(study.panel) %>% 
  # changed fromLon & Lat to fromCountyLon & Lat
  group_by(interval60, from_id, from_station, Origin.County, fromCountyLon, fromCountyLat,delay_minutes) %>%
  summarize(Trip_Count = sum(Trip_Counter, na.rm=T)) %>%
  ungroup() %>%
  filter(is.na(from_id) == FALSE) %>%
  mutate(week = week(interval60),
         dotw = wday(interval60, label = TRUE)) %>%
  filter(is.na(Origin.County) == FALSE) %>%
  # left_join(study.panel, threeStates %>%
  #             as.data.frame()) %>% # extra parenthesis
              # select(-geometry), by = c("Origin.Tract" = "GEOID")) %>%
  arrange(from_id, interval60) %>% 
  mutate(lagHour = dplyr::lag(delay_minutes,1),
         lag2Hours = dplyr::lag(delay_minutes,2),
         lag3Hours = dplyr::lag(delay_minutes,3),
         lag4Hours = dplyr::lag(delay_minutes,4),
         lag12Hours = dplyr::lag(delay_minutes,12),
         lag1day = dplyr::lag(delay_minutes,24)) %>%
         # # Indigenous Peoples' (Columbus) Day is federally recognized
         # #  but not an official city holiday of Austin
         # ## I include it to account for holiday lag
         # holiday = ifelse(yday(interval60) == 282,1,0)) %>%
   mutate(day = yday(interval60)) # %>%
   # mutate(holidayLag = case_when(dplyr::lag(holiday, 1) == 1 ~ "PlusOneDay",
   #                               dplyr::lag(holiday, 2) == 1 ~ "PlusTwoDays",
   #                               dplyr::lag(holiday, 3) == 1 ~ "PlusThreeDays",
   #                               dplyr::lead(holiday, 1) == 1 ~ "MinusOneDay",
   #                               dplyr::lead(holiday, 2) == 1 ~ "MinusTwoDays",
   #                               dplyr::lead(holiday, 3) == 1 ~ "MinusThreeDays"),
   #       holidayLag = ifelse(is.na(holidayLag) == TRUE, 0, holidayLag))

```



<<<<<<< HEAD
### Station Depature Tracking

The table provides a comprehensive list of all stations and the amount of departures they have every 60 minutes, we use these amounts to measure business and tracking individuals trains in the model, predicting if a delay on one station will consequently cause additional delays later in the sequence. 
=======
### timelapse of reliability (week) --REMOVE HEADER
>>>>>>> 97bf75e09dcc79ad761d71adbf2569f16d276655

```{r timelapse_beg,eval=F,include=F}
may_w_stations %>% 
  # merge(y=census,by.x="Origin.County",by.y="GEOID") %>%
  group_by(interval60, from_station, geometry.x, from_id) %>% 
  tally() %>% 
  rename(departures = n) %>%
  st_as_sf() %>%
  st_transform(crs = st_crs(nj_trans_stations))

plotCheckoutData <- may_w_stations[yday(may_w_stations$interval60)==138,] %>% 
  # merge(y=census,by.x="Origin.County",by.y="GEOID") %>% 
  group_by(interval60, from_station, geometry.x, from_id) %>% 
  tally() %>% 
  rename(departures = n) %>%
  st_as_sf() %>%
  st_transform(crs = st_crs(nj_trans_stations))
  
plotReturnData <- may_w_stations[yday(may_w_stations$interval60)==138,] %>% 
  # merge(y=census,by.x="Destination.County",by.y="GEOID") %>% 
  group_by(interval60, to_station, geometry.x,to_id) %>% 
  tally() %>% 
  rename(arrivals = n) %>%
  st_as_sf() %>%
  st_transform(crs = st_crs(nj_trans_stations))
```

### Timelapse 1 

```{r depart_animation,eval=F,include=F}
ggplot()+
  geom_sf(data = plotCheckoutData,color="white",fill="beige")+
  transition_null()+
  geom_sf(data = plotCheckoutData,color="white",aes(fill = departures))+
  # geom_sf(data = cPoints[cPoints$interval60 %in% plotCheckoutData$interval60,],color=GRAY9)+
  plotTheme()+
  # theme(panel.background = "beige",
        # axis.text = element_blank())+
  scale_fill_viridis(direction=-1,option="C",discrete=F)+
  labs(title="Train Trips by Origin County, May, 2020")+
  transition_manual(interval60,fps=100)
  # coord_sf(crs = st_crs(plotCheckoutData), datum = NA)



```

<<<<<<< HEAD

### Timelapse 2

```{r return_animation, eval=F,include=F}


ggplot()+
  geom_sf(data = plotReturnData,color="white",fill="beige")+
  transition_null()+
  geom_sf(data = plotReturnData,color="white",aes(fill = returns))+
  # geom_sf(data = rPoints[rPoints$interval60 %in% plotReturnData$interval60,],color=GRAY9)+
  plotTheme()+
   # theme(panel.background = "beige",
        # axis.text = element_blank())+
  scale_fill_viridis(direction=-1,option="C",discrete=F)+
  labs(title="Train Trips by Destination County, May, 2020")+
  transition_manual(interval60)

```


### Predicting Delay Time and Significance

As data about the NJ Transit train infrastructure and specific trips were analyzed alongside introducing relevant outside information, the decision for two predictive models--one linear model and a binomial logistic regression model--was made followed by their constituent features. The aim of our two models is to predict the length of the delays and the probability of that delay occurring. Train riders desire information regarding delays when it can alter trip plans and is a likely scenario. For our metrics, we are looking at delays that are greater than 10 minutes and have a 50% chance or higher of being delayed. For our approach, we created multiple linear models that would assess features such as the time of the delay, location, temporal lags, and combinations of such.

Model A focused on previous delays, day of the week, and measuring time lags at  60 minute intervals. 

Model B focused on station location and day of the week.

Model C focused on day of the week and time lags of 1, 2, 3, 12, and 24 hour intervals. 

Model D incorporated Models A,B, and C into one. 

*   <ins>**The Linear Model**</ins>
  -   why, number, features included(?)
  -   The choice to train the data on the month of April 
*   <ins>**The Logistic Model**</ins>
  -   why, how linear model focused it, input(?)
*   <ins>**Features**</ins>
  -   list, why


```{r model_trial}

ride.Train <- ride.panelA
ride.Test <- ride.panelM

# ride.Full <- rbind(ride.Train,ride.Test)
# fullPartition <- createDataPartition(
#               y = paste(ride.Full$line), 
#               p = 0.6060172, list = FALSE)

```

```{r five_models }
# uniqueLine <- ride.Test[ride.Test$line=="SILVER STAR  -R",]
# i <- sample(1:nrow(uniqueLine),size=1)
# ride.Train <- rbind(ride.Train,uniqueLine[i,])
# ride.All <- rbind(ride.Train,ride.Test)

reg1 <- 
  lm(delay_minutes ~  hour(interval60) + dotw,  data=ride.Train)

reg2 <- 
  lm(delay_minutes ~  from_id + to_id + dotw,  data=ride.Train) # + line_length,

# reg3 <- 
#   lm(Trip_Count ~  from_id + hour(interval60) + dotw + Temperature + Precipitation, 
#      data=ride.Train)

reg4 <- 
  lm(delay_minutes ~  hour(interval60) + dotw + 
                   lagHour + lag2Hours +lag3Hours + lag12Hours + lag1day, 
     data=ride.Train)

reg5 <- 
  lm(delay_minutes ~  from_id + to_id + hour(interval60) + dotw + # line_length +
                   lagHour + lag2Hours +lag3Hours +lag12Hours + lag1day, 
     data=ride.Train)
```

## Test set Predictions


```{r nest_data , warning = FALSE, message = FALSE}
ride.Test.weekNest <- 
  ride.Test %>%
  nest(-week) 

# predict function
model_pred <- function(dat, fit){
   pred <- predict(fit, newdata = dat)}
```

Our models varied in their absolute errors between one another but stayed consistent throughout each week. Model B, having an emphasis on location (specifically Origin Destination) had the lowest error among all weeks, as our most accurate model. However, Model A, emphasizing lengths in previous delays, had the lowest standard deviation in its errors, being our most precise model. Both Models A (ATime_FE) and B (B_OriginDest_FE) had the most ideal results between standard deviation and mean absolute error, respectively. 

```{r do_predictions, max.height ='120px'}
week_predictions <- 
  ride.Test.weekNest %>% 
    mutate(ATime_FE = map(.x = data, fit = reg1, .f = model_pred),
           BOrigin_Dest_FE = map(.x = data, fit = reg2, .f = model_pred),
           # CTime_Space_FE = map(.x = data, fit = reg3, .f = model_pred),
           CTime_FE_timeLags = map(.x = data, fit = reg4, .f = model_pred),
           DTime_Origin_Dest_FE_timeLags = map(.x = data, fit = reg5, .f = model_pred)) %>% 
    gather(Regression, Prediction, -data, -week) %>%
    mutate(Observed = map(data, pull, Trip_Count),
           Absolute_Error = map2(Observed, Prediction,  ~ abs(.x - .y)),
           MAE = map_dbl(Absolute_Error, mean, na.rm = TRUE),
           sd_AE = map_dbl(Absolute_Error, sd, na.rm = TRUE))

week_predictions[,c(1,3,7:8)] %>% kable() %>% kable_styling()
```

## Examining Accuracy and Generalizability

<<<<<<< HEAD
Throughout the weeks, each model was consistent in their errors and reporting. Model A has the highest absolute error but was consistent throughout each week. Model B was the most accurate, and Models C and D were a middle-ground comparatively to A and B, but fluctuated slightly each week. For the purposes of a train timing, Model B appears to be the best model. 
=======
The best models are models B and D, On the specific May 2020 testing set, the simple model (B) performs the best with consistently low error of 1 minute across each week and across the overall month. The complex model (D) performs second-best in the test data ranging from 1-2 minute errors in predictions in each week or about 2 minutes and 10 seconds for the month of May 2020. The bar charts below denote the MAE or average error of the predicted delay time in minutes by each regression model tested. 
>>>>>>> 97bf75e09dcc79ad761d71adbf2569f16d276655

```{r plot_errors_by_model }
week_predictions %>%
  dplyr::select(week, Regression, MAE) %>%
  gather(Variable, MAE, -Regression, -week) %>%
  ggplot(aes(week, MAE,fill = Regression)) + 
    geom_bar(aes(fill = Regression), position = "dodge", stat="identity",color=BLUE4) +
  geom_text(aes(label=round(MAE,2),group = Regression),color="white",vjust=1.5, position = position_dodge(width = .9),size=3)+
    scale_fill_manual(values = palette5) +
    labs(title = "Mean Absolute Errors by model specification and week") +
  plotTheme() + theme(axis.text.x = element_blank(),axis.text.y = element_blank())

week_predictions %>%
  group_by(Regression)%>%
  summarise(MAE = mean(MAE,na.rm=T))%>%
  dplyr::select(Regression, MAE) %>%
  gather(Variable, MAE, -Regression) %>%
  ggplot(aes(x=Regression,y=MAE)) + 
    geom_bar(aes(fill = Regression), position = "dodge", stat="identity",color=BLUE4) +
  geom_text(aes(label=round(MAE,2)),color="white",vjust=1.5)+
    scale_fill_manual(values = palette5) +
    labs(title = "Mean Absolute Errors by model specification for May 2023") +
  plotTheme() + theme(axis.text.x = element_blank(),axis.text.y = element_blank())
```

##### unchanged code

**Haven't Gotten Here**
```{r error_vs_actual_timeseries , warning = FALSE, message = FALSE,eval=F}
week_predictions %>% 
    mutate(interval60 = map(data, pull, interval60),
           checkout_kiosk_id = map(data, pull, checkout_kiosk_id)) %>%
    dplyr::select(interval60, checkout_kiosk_id, Observed, Prediction, Regression) %>%
    unnest() %>%
    gather(Variable, Value, -Regression, -interval60, -checkout_kiosk_id) %>%
    group_by(Regression, Variable, interval60) %>%
    summarize(Value = sum(Value)) %>%
    ggplot(aes(interval60, Value, colour=Variable)) + 
      geom_line(size = 1.1) + 
      facet_wrap(~Regression, ncol=1) +
      labs(title = "Predicted/Observed bike share time series", subtitle = "Austin; A test set of X weeks",  x = "Hour", y= "Station Trips") +
      plotTheme()
```


```{r errors_by_station, warning = FALSE, message = FALSE,eval=F}
week_predictions %>% 
    mutate(interval60 = map(data, pull, interval60),
           checkout_kiosk_id = map(data, pull, checkout_kiosk_id), 
           from_latitude = map(data, pull, from_latitude), 
           from_longitude = map(data, pull, from_longitude)) %>%
    select(interval60, checkout_kiosk_id, from_longitude, from_latitude, Observed, Prediction, Regression) %>%
    unnest() %>%
  filter(Regression == "ETime_Space_FE_timeLags_holidayLags") %>%
  group_by(checkout_kiosk_id, from_longitude, from_latitude) %>%
  summarize(MAE = mean(abs(Observed-Prediction), na.rm = TRUE))%>%
ggplot(.)+
  geom_sf(data = austinCensus, color = "grey", fill = "transparent")+
  geom_point(aes(x = from_longitude, y = from_latitude, color = MAE), 
             fill = "transparent", alpha = 0.4)+
  scale_colour_viridis(direction = 1,
  discrete = FALSE, option = "H")+
  ylim(min(dat_census$from_latitude), max(dat_census$from_latitude))+
  xlim(min(dat_census$from_longitude), max(dat_census$from_longitude))+
  labs(title="Mean Abs Error, Test Set, Model 5")+
  mapTheme()
```

### Generalizability Measured through Temporal K-Fold

To ensure our model's integrity we conducted cross-validations among Model B and Model D. We used these two models because Model B was the most accurate while Model D was most generalized, incorporating all other models into its regression. Model B  has a consistently low absolute error with a few notable spikes. These are okay because we see a majority of the samples have a consistent range, verifying the model's accuracy. Model D's cross validations has more outliers across the samples which was reflected in previous graphs. Model D does not have the same level of reliability because of its larger number of spikes.


```{r cross-validation}

# reg.vars <- c("checkout_kiosk_id", "hour(interval60)", "dotw", "Temperature", "Precipitation",
#                    "lagHour", "lag2Hours","lag3Hours","lag12Hours", "lag1day", "holidayLag", "holiday")
# 
# reg.CV <- crossValidate(
#   dataset = ride.Train %>% st_as_sf(sf_column_name = "Origin.Tract"),
#   id = "cvID",                           
#   dependentVariable = "Trip_Count",
#   indVariables = reg.vars) %>%
#     dplyr::select(cvID = checkout_kiosk_id, Trip_Count)

reg.cv <-
  train(delay_minutes ~  from_id + to_id + hour(interval60) + dotw, # + line_length +
                   # lagHour + lag2Hours +lag3Hours +lag12Hours + lag1day, 
     data=ride.Train,
        method = "lm",
        trControl = trainControl(method="cv",number=100),
        na.action = na.omit)

reg.cvBest <-
  train(delay_minutes ~  from_id + to_id + hour(interval60) + dotw + line_length +
                   lagHour + lag2Hours +lag3Hours +lag12Hours + lag1day,
     data=ride.Train,
        method = "lm",
        trControl = trainControl(method="cv",number=100),
        na.action = na.omit)

# ggplot(data = reg.cv$resample[1:nrow(reg.cv$resample),])+
#   geom_histogram(aes(x=MAE),fill="orange",color="pink",bins=35)+
#      labs(title = "Distribution of MAE",
#           subtitle = "k-fold cross-validation; k = 100",
#           xlab("Mean Absolute Error"))+
#   coord_cartesian(xlim = c(round(min(reg.cv$resample[3]),-3), round(max(reg.cv$resample[3]),-3)))
#      plotTheme()
     
  ggplot(reg.cv$resample) + 
    geom_bar(fill = "lightgreen",aes(y=MAE,x=Resample), position = "dodge", stat="identity",color=BLUE4) +
    scale_fill_manual(values = palette5) +
    labs(title = "100-fold Cross Validation Sample MAEs - Model B") +
  plotTheme()+theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(),axis.ticks.x = element_blank(),axis.text.x = element_blank())+xlab(label = "Sample Number (1 to 100)")
  
   ggplot(reg.cvBest$resample) + 
    geom_bar(fill = "lightgreen",aes(y=MAE,x=Resample), position = "dodge", stat="identity",color=BLUE4) +
    scale_fill_manual(values = palette5) +
    labs(title = "100-fold Cross Validation Sample MAEs - Model D") +
  plotTheme()+theme(panel.grid.major = element_blank(),panel.grid.minor = element_blank(),axis.ticks.x = element_blank(),axis.text.x = element_blank())+xlab(label = "Sample Number (1 to 100)")
```

## Logistic Model Analysis 

The purpose of the Logistical Model is to predict the probability of each delay occurring. Our dependent variable (delay of 10 minutes), has been compared to by all potential independent variables and features where we find which are most significant in determining the likelihood of the delay occurring. The logistical model is meant to compliment the linear regression model in that while the consequences of delays at specific stations vary, there is different likelihoods of each delay occurring because of the circumstances at each stations. An example can include stations further from major cities may have larger delays but a lower probability of them occurring. 

Similarly to our Regression Model approach, we created two logistical models we classified as Simple and Complex. 

The simple model focuses only on location and if the delays was 10 minutes or not. The complex model factors in everything given within the dataset including the delay length, location, distance between stations, etc. 

```{r logistic}
ride.TrainLog <- ride.Train %>% 
  mutate(delay10 = ifelse(delay_minutes >=10,1,ifelse(!is.na(delay_minutes),0,NA)))

ride.TestLog <- ride.Test %>% 
  mutate(delay10 = ifelse(delay_minutes >=10,1,ifelse(!is.na(delay_minutes),0,NA)))

ride.AllLog <- rbind(ride.TrainLog,ride.TestLog)

reg2Model <- glm(delay10 ~ .,
                  data=as.data.frame(ride.TrainLog %>% 
                    dplyr::select(from_id,to_id,dotw,delay10) %>%
                      st_drop_geometry()),
                  family="binomial" (link="logit"))

reg5Model <- glm(delay10 ~ .,
                  data=as.data.frame(ride.TrainLog %>% 
                    dplyr::select(-from_station,-to_station,-delay_minutes,-line_length,
                                  -Trip_Count,-geometry.x,-week,-day)%>%
                      st_drop_geometry()),
                  family="binomial" (link="logit"))


stargazer(reg2Model,reg5Model,type="text")
```


### Outcomes

The two tables show the difference between what the simple and complex model predicted. A 0 represents no delay while a 1 represents a delay occurring. Both models have a 50% threshold where if the chance of a delay is 50% or greater, the model assumes the delay is occurring. 

```{r probs}

testProbs2 <- data.frame(Outcome = as.factor(ride.TestLog$delay10),
                        Probs = predict(reg2Model, ride.TestLog, type= "response"))

testProbs2_full <- data.frame(Outcome = as.factor(ride.AllLog$delay10),
                        Probs = predict(reg2Model, ride.AllLog, type= "response"))

testProbs5 <- data.frame(Outcome = as.factor(ride.TestLog$delay10),
                        Probs = predict(reg5Model, ride.TestLog, type= "response"))


testProbs5_full <- data.frame(Outcome = as.factor(ride.AllLog$delay10),
                        Probs = predict(reg5Model, ride.AllLog, type= "response"))

testProbs2 <- 
  testProbs2 %>%
  mutate(
    # for 0.5 threshold
    predOutcome  = as.factor(ifelse(testProbs2$Probs > 0.5 , 1, 0))
    )

testProbs2_full <- 
  testProbs2_full %>%
  mutate(
    # for 0.5 threshold
    predOutcome  = as.factor(ifelse(testProbs2_full$Probs > 0.5 , 1, 0))
    )

testProbs5 <- 
  testProbs5 %>%
  mutate(
    # for 0.5 threshold
    predOutcome  = as.factor(ifelse(testProbs5$Probs > 0.5 , 1, 0))
    )

testProbs5_full <- 
  testProbs5_full %>%
  mutate(
    # for 0.5 threshold
    predOutcome  = as.factor(ifelse(testProbs5_full$Probs > 0.5 , 1, 0))
    )

simple <- caret::confusionMatrix(testProbs2$predOutcome, testProbs2$Outcome,
                       positive = "1")

complex <- caret::confusionMatrix(c(testProbs5$predOutcome), c(testProbs5$Outcome),
                       positive = "1")

simple$table
complex$table

```

```{r densities}

AUC2 <- auc(testProbs2$Outcome, testProbs2$Probs)

AUC5 <- auc(testProbs5$Outcome, testProbs5$Probs)

```


**Rename these graphs to reference model names in tables above**
```{r rocs}

ggarrange(nrow=2,
# kitchen sink densities
ggplot(testProbs2, aes(x = Probs, fill = as.factor(Outcome))) + 
  geom_density() +
  facet_grid(Outcome ~ .) +
  scale_fill_manual(values = palette2) +
  labs(x = "Program Entry", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome",
       subtitle = "Model B") +
  theme(strip.text.x = element_text(size = 18),
        legend.position = "none"),

# engineered densities
ggplot(testProbs5, aes(x = Probs, fill = as.factor(Outcome))) + 
  geom_density() +
  facet_grid(Outcome ~ .) +
  scale_fill_manual(values = palette2) +
  labs(x = "Program Entry", y = "Density of probabilities",
       title = "Distribution of predicted probabilities by observed outcome",
       subtitle = "Model D") +
  theme(strip.text.x = element_text(size = 18),
        legend.position = "none"))


ggarrange(nrow=2,
# roc_curve_reg2
ggplot(testProbs2, aes(d = as.numeric(Outcome), m = Probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - Reg2"),

# roc_curve_reg5
ggplot(testProbs5, aes(d = as.numeric(Outcome), m = Probs)) +
  geom_roc(n.cuts = 50, labels = FALSE, colour = "#FE9900") +
  style_roc(theme = theme_grey) +
  geom_abline(slope = 1, intercept = 0, size = 1.5, color = 'grey') +
  labs(title = "ROC Curve - Reg5")
)

```

```{r pred_mean}
r5p <- lapply(week_predictions[week_predictions$Regression=="DTime_Origin_Dest_FE_timeLags",]$Prediction,mean,na.rm=T)[c(1:3)]

r5o <- lapply(week_predictions[week_predictions$Regression=="DTime_Origin_Dest_FE_timeLags",]$Observed,mean,na.rm=T)[c(1:3)]

r5meanP <- mean(c(r5p[[1]],r5p[[2]],r5p[[3]]))
r5meanO <- mean(c(r5o[[1]],r5o[[2]],r5o[[3]]))

r2p <- lapply(week_predictions[week_predictions$Regression=="BOrigin_Dest_FE",]$Prediction,mean,na.rm=T)[c(1:3)]
r2o <- lapply(week_predictions[week_predictions$Regression=="BOrigin_Dest_FE",]$Observed,mean,na.rm=T)[c(1:3)]

r2meanP <- mean(c(r2p[[1]],r2p[[2]],r2p[[3]]))
r2meanO <- mean(c(r2o[[1]],r2o[[2]],r2o[[3]]))


## numbers for below threshold (10 minutes) is larger than valid row count, will stop working for now

# past_thresh <- nrow(ride.TestLog[ride.TestLog$delay10==1,])
# below_thresh <- nrow(ride.TestLog[ride.TestLog$delay10==0,])
# # print(past_thresh+below_thresh==nrow(ride.TestLog[is.na(ride.TestLog$delay10)==F,]))
# below_thresh/nrow(ride.TestLog[is.na(ride.TestLog$delay10)==F,])

```

The simple model considering only the day of the week and the trip's origin and destination has a mean predicted delay of **`r round(r2meanP,0)` minutes and `r round(r2meanP %% 1 * 60,0)` seconds**, and the complex model considering previous factors and time lags has a mean predicted delay of **`r round(r5meanP,0)` minutes and `r round(r5meanP %% 1 * 60,0)` seconds** while the true average observed delay is **`r round(r5meanO,0)` minutes and `r round(r5meanO %% 1 * 60,5)` seconds** for May.